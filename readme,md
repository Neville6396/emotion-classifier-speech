# 🎙️ Emotion Classifier from Speech using Deep Learning

This project is an end-to-end speech emotion recognition system using deep learning (CNN + BiLSTM) to classify emotions from voice recordings.

---

## 📁 Dataset

We use a subset of the RAVDESS dataset including the following 8 emotions:

- angry
- calm
- disgust
- fearful
- happy
- neutral
- sad
- surprised

---

## 🧪 Preprocessing

- Extracted MFCC features (40 coefficients)
- Reshaped MFCCs to (10, 4, 1) for CNN input
- Applied data augmentation:
  - Pitch shifting
  - Time stretching

---

## 🧠 Model Architecture

We use a hybrid CNN + BiLSTM model:

- 2D CNN Layer
- MaxPooling + Dropout
- Reshape for sequential input
- BiLSTM (Bidirectional)
- Dense + Softmax layer

**Loss:** Focal Loss  
**Optimizer:** Adam  
**Callback:** EarlyStopping

---

## 📊 Evaluation Metrics

| Metric | Target | Achieved |
|--------|--------|----------|
| Overall Accuracy | > 80% | ✅ 88% |
| F1-score (macro avg) | > 80% | ✅ 88% |
| Per-class Accuracy | > 75% | ✅ All classes met |

**Confusion Matrix and Classification Report available in notebook.**

---

## 🚀 How to Use

### A. Test from command line

```bash
python predict_emotion.py path_to_audio.wav
